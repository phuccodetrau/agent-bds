{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import string\n",
    "import logging\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "import underthesea\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import col, udf, lit, greatest, monotonically_increasing_id, concat_ws\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DoubleType, StructType, StructField, MapType, BooleanType\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, MinHashLSH\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/03 12:50:53 WARN Utils: Your hostname, haihp02 resolves to a loopback address: 127.0.1.1; using 192.168.102.7 instead (on interface wlp5s0)\n",
      "24/01/03 12:50:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/03 12:50:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.102.7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://172.24.0.11:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe0f4c5e310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"spark://172.24.0.11:7077\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext._jsc.sc().getExecutorMemoryStatus().keySet().size())\n",
    "# spark.sparkContext.setLogLevel(\"DEBUG\")\n",
    "# logging.getLogger(\"py4j\").setLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hdfs_file_path = [\n",
    "    'hdfs://192.168.102.7:10000/haihp02/real_estate_data/bds.jsonl',\n",
    "    'hdfs://192.168.102.7:10000/haihp02/real_estate_data/i-batdongsan.jsonl',\n",
    "    'hdfs://192.168.102.7:10000/haihp02/real_estate_data/nhadatviet.jsonl',\n",
    "]\n",
    "df = spark.read.json(hdfs_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+--------------------+----------+------------------+--------------------+-----------------+--------------------+\n",
      "|summary|         description|     estate_type|                link| post_date|           post_id|               price|           square|               title|\n",
      "+-------+--------------------+----------------+--------------------+----------+------------------+--------------------+-----------------+--------------------+\n",
      "|  count|              250796|          240015|              250796|    250796|            250796|              248964|           247809|              250795|\n",
      "|   mean|                NULL|            NULL|                NULL|      NULL|3759772.4077058644|6.948346463197141E14|16837.76337179037|                NULL|\n",
      "| stddev|                NULL|            NULL|                NULL|      NULL|2288274.0038934583|1.409071832582140...| 5107081.44598701|                NULL|\n",
      "|    min|                    |        Bi·ªát th·ª±|https://123nhadat...|2019/12/25|            100017|          -450 tri·ªáu|              0.0|                    |\n",
      "|    max|ü´∂ ü´∂ ü´∂ CCMN L√î ...|ƒê·∫•t n·ªÅn, ph√¢n l√¥|https://i-batdong...|2023/11/19|             99955|          th·ªèa thu·∫≠n|    2.147483647E9|ü´∞ M·∫∂T NG√ï 39.6 M...|\n",
      "+-------+--------------------+----------------+--------------------+----------+------------------+--------------------+-----------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
