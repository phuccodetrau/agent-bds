{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import string\n",
    "import logging\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "import underthesea\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import col, udf, lit, greatest, monotonically_increasing_id, concat_ws\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DoubleType, StructType, StructField, MapType, BooleanType\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, MinHashLSH\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/03 18:51:59 WARN Utils: Your hostname, haihp02 resolves to a loopback address: 127.0.1.1; using 192.168.102.7 instead (on interface wlp5s0)\n",
      "24/01/03 18:51:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/03 18:52:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/01/03 18:52:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# spark = SparkSession.builder.master(\"spark://172.24.0.11:7077\").getOrCreate()\n",
    "spark = SparkSession.builder.appName('streaming').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hdfs_file_path = [\n",
    "    'hdfs://192.168.102.7:10000/haihp02/real_estate_data/bds.jsonl',\n",
    "    'hdfs://192.168.102.7:10000/haihp02/real_estate_data/i-batdongsan.jsonl',\n",
    "    'hdfs://192.168.102.7:10000/haihp02/real_estate_data/nhadatviet.jsonl',\n",
    "]\n",
    "df = spark.read.json(hdfs_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- address: struct (nullable = true)\n",
      " |    |-- district: string (nullable = true)\n",
      " |    |-- full_address: string (nullable = true)\n",
      " |    |-- province: string (nullable = true)\n",
      " |    |-- ward: string (nullable = true)\n",
      " |-- contact_info: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- phone: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- estate_type: string (nullable = true)\n",
      " |-- extra_infos: struct (nullable = true)\n",
      " |    |-- Chiều dài: string (nullable = true)\n",
      " |    |-- Chiều ngang: string (nullable = true)\n",
      " |    |-- Chính chủ: boolean (nullable = true)\n",
      " |    |-- Chổ để xe hơi: boolean (nullable = true)\n",
      " |    |-- Hướng: string (nullable = true)\n",
      " |    |-- Loại tin: string (nullable = true)\n",
      " |    |-- Lộ giới: string (nullable = true)\n",
      " |    |-- Nhà bếp: boolean (nullable = true)\n",
      " |    |-- Pháp lý: string (nullable = true)\n",
      " |    |-- Phòng ăn: boolean (nullable = true)\n",
      " |    |-- Sân thượng: boolean (nullable = true)\n",
      " |    |-- Số lầu: string (nullable = true)\n",
      " |    |-- Số phòng ngủ: string (nullable = true)\n",
      " |    |-- Số phòng ngủ :: string (nullable = true)\n",
      " |    |-- Số toilet :: string (nullable = true)\n",
      " |    |-- Tầng :: string (nullable = true)\n",
      " |-- link: string (nullable = true)\n",
      " |-- post_date: string (nullable = true)\n",
      " |-- post_id: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- square: double (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250796"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De-duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('Id', monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"text\", concat_ws(' ', col('title'), col('description')))\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "df = tokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"tokens\", outputCol=\"tf\")\n",
    "df = hashingTF.transform(df)\n",
    "\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"tfidf\")\n",
    "idf_model = idf.fit(df)\n",
    "df = idf_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_non_zero_udf = udf(lambda v: Vectors.sparse(len(v) + 1, list(v.indices) + [len(v)], list(v.values) + [1e-5]), VectorUDT())\n",
    "\n",
    "df = df.withColumn(\"tfidf\", append_non_zero_udf(col(\"tfidf\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/02 22:48:16 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n"
     ]
    }
   ],
   "source": [
    "num_hash_tables = 5\n",
    "minhashLSH = MinHashLSH(inputCol=\"tfidf\", outputCol=\"hashes\", numHashTables=num_hash_tables)\n",
    "model = minhashLSH.fit(df)\n",
    "df_duplicates = model.approxSimilarityJoin(df.select(\"Id\", \"tfidf\"), df.select(\"Id\", \"tfidf\"), 0.8, distCol=\"JaccardDistance\") \\\n",
    "    .filter(\"datasetA.id < datasetB.id\")  # Avoid comparing a row to itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/02 22:48:17 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/01/02 22:48:18 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|            datasetA|            datasetB|   JaccardDistance|\n",
      "+--------------------+--------------------+------------------+\n",
      "|{6, (262145,[191,...|{16, (262145,[191...|0.7549019607843137|\n",
      "|{6, (262145,[191,...|{14, (262145,[191...|0.6513761467889908|\n",
      "|{13, (262145,[7,4...|{15, (262145,[191...|0.7669902912621359|\n",
      "|{11, (262145,[191...|{12, (262145,[704...|0.7272727272727273|\n",
      "|{3, (262145,[191,...|{18, (262145,[191...|0.5189873417721519|\n",
      "|{2, (262145,[191,...|{18, (262145,[191...|0.7213114754098361|\n",
      "|{3, (262145,[191,...|{6, (262145,[191,...|0.5544554455445545|\n",
      "|{14, (262145,[191...|{16, (262145,[191...|0.6578947368421053|\n",
      "|{2, (262145,[191,...|{15, (262145,[191...|0.7355371900826446|\n",
      "|{16, (262145,[191...|{18, (262145,[191...|0.7272727272727273|\n",
      "|{4, (262145,[191,...|{13, (262145,[7,4...|0.7966101694915254|\n",
      "|{5, (262145,[191,...|{13, (262145,[7,4...|0.7699115044247787|\n",
      "|{6, (262145,[191,...|{17, (262145,[191...|0.6388888888888888|\n",
      "|{6, (262145,[191,...|{18, (262145,[191...|0.6116504854368932|\n",
      "|{18, (262145,[191...|{19, (262145,[191...|              0.36|\n",
      "|{0, (262145,[191,...|{3, (262145,[191,...|0.6989247311827957|\n",
      "|{0, (262145,[191,...|{17, (262145,[191...|0.6444444444444444|\n",
      "|{4, (262145,[191,...|{16, (262145,[191...| 0.735632183908046|\n",
      "|{10, (262145,[191...|{12, (262145,[704...|0.7948717948717949|\n",
      "|{1, (262145,[191,...|{7, (262145,[191,...|0.6206896551724138|\n",
      "+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/02 22:48:19 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    }
   ],
   "source": [
    "df_duplicates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = df.join(remove_ids, df[\"Id\"] == remove_ids[\"id\"], \"leftanti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/02 22:53:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/01/02 22:53:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/01/02 22:53:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+------------+--------------------+--------------------+----------+-------+----------+------+--------------------+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|             address|        contact_info|         description| estate_type|         extra_infos|                link| post_date|post_id|     price|square|               title| Id|                text|              tokens|                  tf|               tfidf|\n",
      "+--------------------+--------------------+--------------------+------------+--------------------+--------------------+----------+-------+----------+------+--------------------+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|{Hai Bà Trưng, đư...|{Lại Tiến Dũng, [...|Dòng tiền ổn định...|Nhà ngõ, hẻm|{10.7m, 4.2m, Đôn...|https://guland.vn...|2023/05/29| 464352|5500000000|    45|Dòng tiền ổn định...|  7|Dòng tiền ổn định...|[dòng, tiền, ổn, ...|(262144,[191,1344...|(262145,[191,1344...|\n",
      "|{Hai Bà Trưng, đư...|{Ngô Thị Thuỷ, [0...|Bán nhà ngõ 191 M...|Nhà ngõ, hẻm|{10m, 3.6m, Nam, ...|https://guland.vn...|2023/05/29| 463917|3450000000|    36|Bán nhà ngõ 191 M...| 19|Bán nhà ngõ 191 M...|[bán, nhà, ngõ, 1...|(262144,[191,8808...|(262145,[191,8808...|\n",
      "+--------------------+--------------------+--------------------+------------+--------------------+--------------------+----------+-------+----------+------+--------------------+---+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/02 22:53:34 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_special_chars(df: pyspark.sql.dataframe.DataFrame):\n",
    "    # get concatenated text\n",
    "    concatenated_text = df.select(f.concat_ws(' ', col('title'), col('description')).alias('concatenated_text'))\n",
    "    all_characters = concatenated_text.rdd.flatMap(lambda x: x[0])\n",
    "    special_characters = all_characters.filter(lambda c: not c.isalnum() and not c.isspace() and not c in string.punctuation)\n",
    "    return set(special_characters.collect())\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def remove_special_chars(input_string, special_chars_list, at_once=False):\n",
    "    if not input_string:\n",
    "        return None\n",
    "    if at_once:\n",
    "        special_chars_string = ''.join(special_chars_list)\n",
    "        translator = str.maketrans('', '', special_chars_string)\n",
    "        result = input_string.translate(translator)\n",
    "    else:\n",
    "        result = input_string\n",
    "        for c in special_chars_list:\n",
    "            result = result.replace(c, '')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "special_chars_list = list(get_special_chars(df))\n",
    "special_chars_lit = lit(special_chars_list)\n",
    "df = df.withColumn(\"title\", remove_special_chars(\"title\", special_chars_lit))\n",
    "df = df.withColumn(\"description\", remove_special_chars(\"description\", special_chars_lit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['→',\n",
       " '\\u202a',\n",
       " '\\uf0d8',\n",
       " '✤',\n",
       " '\\u200c',\n",
       " 'ۣ',\n",
       " '🅖',\n",
       " '–',\n",
       " '₋',\n",
       " '●',\n",
       " '¬',\n",
       " '̶',\n",
       " '▬',\n",
       " '≈',\n",
       " '🫵',\n",
       " '◇',\n",
       " '▷',\n",
       " '🪷',\n",
       " '◊',\n",
       " '‐',\n",
       " '🫴',\n",
       " '\\uf05b',\n",
       " '⦁',\n",
       " '️',\n",
       " '㎡',\n",
       " '🫰',\n",
       " '′',\n",
       " '✥',\n",
       " '✧',\n",
       " '♤',\n",
       " '🫶',\n",
       " 'ۜ',\n",
       " '❃',\n",
       " '̀',\n",
       " '֍',\n",
       " '\\u2060',\n",
       " '\\u206e',\n",
       " '‘',\n",
       " '❈',\n",
       " '🅣',\n",
       " '🅘',\n",
       " '℅',\n",
       " '\\ufeff',\n",
       " '″',\n",
       " '\\u200b',\n",
       " '♚',\n",
       " '̣',\n",
       " '₫',\n",
       " '\\uf06e',\n",
       " '✩',\n",
       " '🅨',\n",
       " '’',\n",
       " '\\xad',\n",
       " '★',\n",
       " '±',\n",
       " '\\U0001fae8',\n",
       " '︎',\n",
       " '\\uf0f0',\n",
       " '∙',\n",
       " '♛',\n",
       " '̉',\n",
       " '̛',\n",
       " '❆',\n",
       " '✜',\n",
       " '÷',\n",
       " '♜',\n",
       " '·',\n",
       " '❖',\n",
       " '】',\n",
       " '❁',\n",
       " '🫱',\n",
       " '・',\n",
       " '€',\n",
       " '☛',\n",
       " '“',\n",
       " '■',\n",
       " '\\uf046',\n",
       " '￼',\n",
       " '�',\n",
       " '\\u200d',\n",
       " '🫠',\n",
       " '\\uf0e8',\n",
       " '⁃',\n",
       " '≥',\n",
       " '～',\n",
       " '➣',\n",
       " '́',\n",
       " '🪩',\n",
       " '̃',\n",
       " '\\uf02b',\n",
       " '᪥',\n",
       " '🪺',\n",
       " '♧',\n",
       " '❂',\n",
       " '。',\n",
       " '♡',\n",
       " '，',\n",
       " '🪸',\n",
       " '：',\n",
       " '¥',\n",
       " '❝',\n",
       " '̂',\n",
       " '\\U0001fa77',\n",
       " '\\uf0a7',\n",
       " 'ৣ',\n",
       " '⚘',\n",
       " '➢',\n",
       " '⇔',\n",
       " '、',\n",
       " '－',\n",
       " '✆',\n",
       " '🫣',\n",
       " '⛫',\n",
       " '►',\n",
       " '̆',\n",
       " '✎',\n",
       " '❯',\n",
       " '《',\n",
       " '\\uf076',\n",
       " '❮',\n",
       " '❀',\n",
       " '̵',\n",
       " '🥹',\n",
       " '❉',\n",
       " '̷',\n",
       " '\\uf028',\n",
       " '✽',\n",
       " '«',\n",
       " '⇒',\n",
       " '➤',\n",
       " '\\uf0e0',\n",
       " '\\U0001faad',\n",
       " '♙',\n",
       " '\\uf0fc',\n",
       " '【',\n",
       " '➥',\n",
       " '¤',\n",
       " '＆',\n",
       " '🛇',\n",
       " '\\x7f',\n",
       " '）',\n",
       " '—',\n",
       " '”',\n",
       " '❞',\n",
       " '》',\n",
       " '☆',\n",
       " '×',\n",
       " '✞',\n",
       " '✿',\n",
       " '≤',\n",
       " '🅐',\n",
       " '√',\n",
       " '°',\n",
       " '✓',\n",
       " '¡',\n",
       " '…',\n",
       " '•',\n",
       " '»',\n",
       " '❊',\n",
       " '➦',\n",
       " '\\u06dd',\n",
       " '\\uf06c',\n",
       " '¸']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_chars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=StringType())\n",
    "def remove_duplicate_punctuation_sequence(input_string):\n",
    "    def remove_duplicate_sequence(text, target_char, max_length):\n",
    "        pattern_1 = re.escape(target_char) + '{' + str(max_length) + ',}'\n",
    "        pattern_2 = '(' + '\\s' + re.escape(target_char) + ')' + '{' + str(max_length) + ',}'\n",
    "        result = re.sub(pattern_2, target_char, re.sub(pattern_1, target_char, text))\n",
    "        return result\n",
    "    \n",
    "    if not input_string:\n",
    "        return None\n",
    "    result = input_string\n",
    "    for punc in string.punctuation:\n",
    "        if punc == '\\\\':\n",
    "            continue\n",
    "        max_length = 3 if punc == '.' else 1\n",
    "        reuslt = remove_duplicate_sequence(result, punc, max_length)\n",
    "    return reuslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"title\", remove_duplicate_punctuation_sequence(\"title\"))\n",
    "df = df.withColumn(\"description\", remove_duplicate_punctuation_sequence(\"description\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estate_types(df: pyspark.sql.dataframe.DataFrame):\n",
    "    df = df.filter(df['estate_type'].isNotNull())\n",
    "    all_estate_types = df.select('estate_type').rdd.map(lambda x: x[0])\n",
    "    estate_types_set = set(all_estate_types.collect())\n",
    "    return estate_types_set\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def normalize_estate_type(input_estate_type):\n",
    "    if not input_estate_type:\n",
    "        return None\n",
    "    estate_type_prefix = ['Cho thuể', 'Mua bán', 'Căn hộ']\n",
    "    estate_type_map = {\n",
    "        'Biệt thự, liền k`ề': 'Biệt thự liền kề',\n",
    "        'Nhà biệt thự liền kề': 'Biệt thự liền kề',\n",
    "        'Nhà mặt phố': 'Nhà mặt tiền',\n",
    "        'Phòng trọ, nhà trọ, nhà trọ': 'Phòng trọ, nhà trọ',\n",
    "        'Phòng trọ': 'Phòng trọ, nhà trọ',\n",
    "        'Trang trại, khu nghỉ dưỡng': 'Trang trại khu nghỉ dưỡng',\n",
    "        'Kho nhà xưởng': 'Kho xưởng',\n",
    "        'Kho, xưởng': 'Kho xưởng'\n",
    "    }\n",
    "    result = input_estate_type\n",
    "    for prefix in estate_type_prefix:\n",
    "        result = result.replace(prefix, '').strip().capitalize()\n",
    "    for estate_type in estate_type_map.keys():\n",
    "        if result == estate_type:\n",
    "            result = estate_type_map[estate_type]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"estate_type\", normalize_estate_type(\"estate_type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=FloatType())\n",
    "def price_normalize(price, square):\n",
    "    if price is None:\n",
    "        return None\n",
    "    if isinstance(price, int) or isinstance(price, float):\n",
    "        return price\n",
    "    elif isinstance(price, str):\n",
    "        if price.isnumeric():\n",
    "            return float(price)\n",
    "        if square is not None:\n",
    "            price = underthesea.text_normalize(price)\n",
    "            # Các trường hợp thực sự điền giá / m2\n",
    "            if 'triệu/ m' in price or 'triệu / m' in price:\n",
    "                price = float(price.split()[0]) * 1e6 * square\n",
    "            # Các trường hợp điền nhầm giá sang giá / m2\n",
    "            elif 'tỷ/ m' in price or 'tỷ / m' in price:\n",
    "                price = float(price.split()[0]) * 1e9\n",
    "            else:\n",
    "                price = None\n",
    "        elif square is None:\n",
    "            price = None\n",
    "    return price\n",
    "\n",
    "def get_lower_upper_bound(df, col_name, lower_percent=5, upper_percent=95, outlier_threshold=5):\n",
    "    lower_percentile, upper_percentile = df.approxQuantile(col_name, [lower_percent/100, upper_percent/100], 0.01)\n",
    "    quantile_range = upper_percentile - lower_percentile\n",
    "    lower_bound = np.max([0, lower_percentile - outlier_threshold * quantile_range])\n",
    "    upper_bound = upper_percentile + outlier_threshold * quantile_range\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "def get_detail_lower_upper_bound(df, col_name, lower_percent=5, upper_percent=95, outlier_threshold=5, overprice=1e15):\n",
    "    quantiles_by_estate_type = (\n",
    "        df.groupBy(\"estate_type\")\n",
    "        .agg(f.percentile_approx(col_name, [lower_percent/100, upper_percent/100], 100).alias(\"percentile_approx\"))\n",
    "    )\n",
    "    quantiles_by_estate_type = quantiles_by_estate_type.withColumn(\"lower_percentile\", col(\"percentile_approx\").getItem(0)) \\\n",
    "                                                       .withColumn(\"upper_percentile\", col(\"percentile_approx\").getItem(1)) \\\n",
    "                                                       .withColumn(\"quantile_range\", col(\"upper_percentile\") - col(\"lower_percentile\"))\n",
    "    quantiles_by_estate_type = quantiles_by_estate_type.withColumn(\"lower_bound\", greatest(col(\"lower_percentile\") - outlier_threshold * col(\"quantile_range\"), lit(0))) \\\n",
    "                                                       .withColumn(\"upper_bound\", col(\"upper_percentile\") + outlier_threshold * col(\"quantile_range\"))\n",
    "    \n",
    "    return quantiles_by_estate_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+----------------+--------------+-----------+-----------+\n",
      "|         estate_type|   percentile_approx|lower_percentile|upper_percentile|quantile_range|lower_bound|upper_bound|\n",
      "+--------------------+--------------------+----------------+----------------+--------------+-----------+-----------+\n",
      "|             Nhà phố|    [4.0E9, 1.22E11]|           4.0E9|         1.22E11|       1.18E11|        0.0|    7.12E11|\n",
      "|           Văn phòng|    [7.8E9, 3.83E11]|           7.8E9|         3.83E11|      3.752E11|        0.0|   2.259E12|\n",
      "|Đất nông, lâm nghiệp|[3000000.0, 1.125...|       3000000.0|        1.125E11|    1.12497E11|        0.0| 6.74985E11|\n",
      "|  Mặt bằng, cửa hàng|     [2.0E7, 1.2E11]|           2.0E7|          1.2E11|     1.1998E11|        0.0|   7.199E11|\n",
      "|   Biệt thự, liền kề|     [6.3E9, 8.0E10]|           6.3E9|          8.0E10|       7.37E10|        0.0|   4.485E11|\n",
      "|    Đất nền, phân lô|     [5.0E8, 3.7E10]|           5.0E8|          3.7E10|       3.65E10|        0.0|   2.195E11|\n",
      "|           Phòng trọ|    [5.7E9, 2.59E10]|           5.7E9|         2.59E10|       2.02E10|        0.0|   1.269E11|\n",
      "| Nhà hàng, khách sạn|    [2.5E8, 2.81E11]|           2.5E8|         2.81E11|     2.8075E11|        0.0| 1.68475E12|\n",
      "|Trang trại, khu n...|     [7.9E8, 6.0E10]|           7.9E8|          6.0E10|      5.921E10|        0.0|  3.5605E11|\n",
      "|       Các loại khác|    [1.08E8, 1.3E11]|          1.08E8|          1.3E11|    1.29892E11|        0.0|  7.7946E11|\n",
      "|           Nhà xưởng|     [9.6E7, 2.5E11]|           9.6E7|          2.5E11|    2.49904E11|        0.0| 1.49952E12|\n",
      "|            Chung cư|     [9.85E8, 7.4E9]|          9.85E8|           7.4E9|       6.415E9|        0.0|  3.9475E10|\n",
      "|           Nhà riêng|    [2.4E9, 1.85E10]|           2.4E9|         1.85E10|       1.61E10|        0.0|     9.9E10|\n",
      "|  Phòng trọ, nhà trọ|     [5.7E9, 2.7E10]|           5.7E9|          2.7E10|       2.13E10|        0.0|   1.335E11|\n",
      "|        Nhà mặt tiền|    [3.35E9, 1.0E11]|          3.35E9|          1.0E11|      9.665E10|        0.0|  5.8325E11|\n",
      "|            Biệt thự|     [6.5E9, 9.5E10]|           6.5E9|          9.5E10|       8.85E10|        0.0|   5.375E11|\n",
      "|          Kho, xưởng|     [7.5E7, 2.5E11]|           7.5E7|          2.5E11|    2.49925E11|        0.0|1.499625E12|\n",
      "|                 Đất|    [5.34E8, 3.3E10]|          5.34E8|          3.3E10|     3.2466E10|        0.0|  1.9533E11|\n",
      "|    Shop, kiot, quán|     [5.8E7, 5.0E10]|           5.8E7|          5.0E10|     4.9942E10|        0.0|  2.9971E11|\n",
      "|          Trang trại|  [2222000.0, 6.7E9]|       2222000.0|           6.7E9|    6.697778E9|        0.0|4.018889E10|\n",
      "+--------------------+--------------------+----------------+----------------+--------------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "get_detail_lower_upper_bound(df, \"price\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extra_info_labels(df):\n",
    "    extra_infos_df = df.select(\"extra_infos\")\n",
    "    extra_infos_labels = extra_infos_df.rdd.flatMap(lambda x: list(x[0].asDict().keys())).collect()\n",
    "    return set(extra_infos_labels)\n",
    "\n",
    "def cast_to_string(value):\n",
    "    try:\n",
    "        return str(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def cast_to_boolean(value):\n",
    "    try:\n",
    "        return bool(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def cast_to_integer(value):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "    \n",
    "def cast_to_float(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "    \n",
    "def normalize_text_field_in_dict(dict_obj):\n",
    "    result_dict = dict_obj\n",
    "    for key in result_dict.keys():\n",
    "        if isinstance(result_dict[key], str):\n",
    "            result_dict[key] = result_dict[key].replace(',', '.')\n",
    "            new_val = ''\n",
    "            for c in result_dict[key]:\n",
    "                if c.isalpha() or c.isnumeric() or c == '.' or c == ' ':\n",
    "                    new_val += c\n",
    "            result_dict[key] = new_val\n",
    "    return result_dict\n",
    "\n",
    "old_keys = ['Chiều dài', 'Chiều ngang', 'Chính chủ', 'Chổ để xe hơi', 'Hướng', 'Loại tin', 'Lộ giới', 'Nhà bếp', 'Pháp lý', 'Phòng ăn', 'Sân thượng', 'Số lầu', 'Số phòng ngủ', 'Số phòng ngủ :', 'Số toilet :', 'Tầng :']\n",
    "new_keys = ['Chiều dài', 'Chiều ngang', 'Chính chủ', 'Chỗ để xe hơi', 'Hướng', 'remove', 'Lộ giới', 'Nhà bếp', 'Pháp lý', 'Phòng ăn', 'Sân thượng', 'Số lầu', 'Số phòng ngủ', 'Số phòng ngủ', 'Số toilet', 'Tầng']\n",
    "remove_keys = ['remove']\n",
    "@udf(returnType=StructType([\n",
    "    StructField('Chiều dài', FloatType()),\n",
    "    StructField('Chiều ngang', FloatType()),\n",
    "    StructField('Chính chủ', BooleanType()),\n",
    "    StructField('Chỗ để xe hơi', BooleanType()),\n",
    "    StructField('Hướng', StringType()),\n",
    "    StructField('Lộ giới', FloatType()),\n",
    "    StructField('Nhà bếp', BooleanType()),\n",
    "    StructField('Pháp lý', StringType()),\n",
    "    StructField('Phòng ăn', BooleanType()),\n",
    "    StructField('Sân thượng', BooleanType()),\n",
    "    StructField('Số lầu', IntegerType()),\n",
    "    StructField('Số phòng ngủ', IntegerType()),\n",
    "    StructField('Số toilet', IntegerType()),\n",
    "    StructField('Tầng', IntegerType()),\n",
    "]))\n",
    "def normalize_extra_infos_dict(input_extra_infos_row, old_keys, new_keys, remove_keys):\n",
    "    old_keys = list(old_keys)\n",
    "    new_keys = list(new_keys)\n",
    "    remove_keys = list(remove_keys)\n",
    "    assert len(old_keys) == len(new_keys)\n",
    "\n",
    "    # Normalize dict keys\n",
    "    extra_infos_dict = input_extra_infos_row.asDict()\n",
    "    dict_nomalized_keys = {}\n",
    "\n",
    "    for old_key, new_key in zip(old_keys, new_keys):\n",
    "        if old_key in extra_infos_dict.keys():\n",
    "            if new_key in dict_nomalized_keys.keys() and dict_nomalized_keys[new_key] is None \\\n",
    "                or new_key not in dict_nomalized_keys.keys():\n",
    "                dict_nomalized_keys[new_key] = extra_infos_dict[old_key]\n",
    "        else:\n",
    "            dict_nomalized_keys[new_key] = None\n",
    "    for key in remove_keys:\n",
    "        if key in dict_nomalized_keys.keys():\n",
    "            dict_nomalized_keys.pop(key)\n",
    "    # Normalize dict values\n",
    "    result_dict = normalize_text_field_in_dict(dict_nomalized_keys)\n",
    "    result_dict['Chiều dài'] = cast_to_float(dict_nomalized_keys['Chiều dài'].replace('m', ''))\n",
    "    result_dict['Chiều ngang'] = cast_to_float(dict_nomalized_keys['Chiều ngang'].replace('m', ''))\n",
    "    result_dict['Chính chủ'] = cast_to_boolean(dict_nomalized_keys['Chính chủ'])\n",
    "    result_dict['Chỗ để xe hơi'] = cast_to_boolean(dict_nomalized_keys['Chỗ để xe hơi'])\n",
    "    result_dict['Hướng'] = cast_to_string(dict_nomalized_keys['Hướng'])\n",
    "    result_dict['Lộ giới'] = cast_to_float(dict_nomalized_keys['Lộ giới'].replace('m', ''))\n",
    "    result_dict['Nhà bếp'] = cast_to_boolean(dict_nomalized_keys['Nhà bếp'])\n",
    "    result_dict['Pháp lý'] = cast_to_string(dict_nomalized_keys['Pháp lý'])\n",
    "    result_dict['Phòng ăn'] = cast_to_boolean(dict_nomalized_keys['Phòng ăn'])\n",
    "    result_dict['Sân thượng'] = cast_to_boolean(dict_nomalized_keys['Sân thượng'])\n",
    "    result_dict['Số lầu'] = cast_to_integer(dict_nomalized_keys['Số lầu'])\n",
    "    result_dict['Số phòng ngủ'] = cast_to_integer(dict_nomalized_keys['Số phòng ngủ'])\n",
    "    result_dict['Số toilet'] = cast_to_integer(dict_nomalized_keys['Số toilet'])\n",
    "    result_dict['Tầng'] = cast_to_integer(dict_nomalized_keys['Tầng'])\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"extra_infos\", normalize_extra_infos_dict(\"extra_infos\", lit(old_keys), lit(new_keys), lit(remove_keys)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
